You need to setup a local LLM for this to work. I use the llama3.1:8b-instruct-q5_K_M for this project.
